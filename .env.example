OPENAI_API_KEY=<not needed when using VicunaLLM>
CHAT_API_URL=http://localhost:5000/api/v1/generate
MEMORIES_PATH=memories/
UPLOAD_PATH=uploads/
DOCUMENT_STORE_NAME=brainchulo_docs
CONVERSATION_STORE_NAME=brainchulo_convos
DATABASE_URL=sqlite:///data/brainchulo.db
ANDROMEDA_URL=http://0.0.0.0:9000/
MODEL_PATH=/airoboros-7B/airoboros-7b-gpt4.ggmlv3.q8_0.bin
USE_FLOW_AGENTS=true
# General Settings
GENERAL_LOADING_METHOD=GPTQ
GENERAL_BOOL_CPU_OFFLOADING=false
# HuggingFace
HF_BOOL_USE_QUANT=true
HF_BOOL_USE_4_BIT=true
# GPTQ
GPTQ_INT_WBITS=4
GPTQ_INT_GROUP_SIZE=128
GPTQ_INT_PRE_LOADED_LAYERS=20
GPTQ_DEVICE="cuda"
# Guidance
GUIDANCE_REASONING_MODEL_PATH=/orca-mini-7B/orca-mini-7b.ggmlv3.q8_0.bin
GUIDANCE_EXTRACTION_MODEL_PATH=/airoboros-7B/airoboros-7b-gpt4.ggmlv3.q8_0.bin
EMBEDDINGS_MODEL=all-MiniLM-L6-v2
TEST_FILE="your_guidance_test_file"
TEST_MODE="OFF"
ETHICS="OFF"
#Development
VITE_BACKEND_BASE_URL=http://localhost:5173/api
NODE_ENV=development
#Prod
#BACKEND_BASE_URL=https://backend.host.io:7865
#NODE_ENV=production
